removed posts
_______

_______

_______

_______

_______

_______

_______
In probability theory and statistics, **variance** is the expectation of the squared deviation of a random variable from its mean. Informally, it measures how far a set of (random) numbers are spread out from their average value.

Source: [Wiki](https://en.wikipedia.org/wiki/Variance)
_______
**Supervised learning** is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.

Source: [Wiki](https://en.wikipedia.org/wiki/Supervised_learning)
_______
SQL stands for Structured Query Language. It is the standard language for querying and manipulating data in relational databases. SQL is designed to be much simpler than earlier methods of accessing databases, and works with a variety of commercial database systems in the market today.

![SQLschema](https://upload.wikimedia.org/wikipedia/commons/2/2d/MediaWiki_1.10_database_schema.png)
_______
In statistics, the standard deviation (SD, also represented by the lower case Greek letter sigma Ïƒ or the Latin letter s) is a measure that is used to quantify the amount of [variation](https://www.dsglossary.com/v/variance) or dispersion of a set of data values. A low standard deviation indicates that the data points tend to be close to the [mean](https://www.dsglossary.com/m/mean) (also called the expected value) of the set, while a high standard deviation indicates that the data points are spread out over a wider range of values.

Source: [Wiki](https://en.wikipedia.org/wiki/Standard_deviation)
_______
- **Data Wranging:** Preparing data data for a specific purpose. Taking data from its raw state and transforming it to another format.
    **Why is it useful?** Raw data can be difficult to analyze and gain insights from. Transforming it into dataframes, rows, columns,                               arrays, etc. to a more userful format allows it to be more easily manipulated and analyzed.
- **Example** The transformed data can be used in Machine Learning to restructure it so it can be used in a learning algorithm.
   - Acquire the Data
   - Data Cleaning

_______
The process of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters).

Cluster analysis itself is not one specific algorithm, but it can be achieved by various algorithms that differ significantly in their understanding of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with small distances between cluster members, dense areas of the data space, intervals or particular statistical distributions. 

The appropriate clustering algorithm and parameter settings (including parameters such as the distance function to use, a density threshold or the number of expected clusters) depend on the individual data set and intended use of the results. Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure. 

![cluster](https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/DBSCAN-Gaussian-data.svg/434px-DBSCAN-Gaussian-data.svg.png)
_______
Also known as Bayes' Rule, Bayes' Theorem is a tool for calculating conditional probabilities. One interpretation is that it is used for calculating the probability of an event in light of new information given some prior belief about its likelihood.

![Bayes' Theorem](http://mathurl.com/yclug444.png "Bayes' Theorem"){: .center-image }
_______

_______

_______

_______

_______

_______


